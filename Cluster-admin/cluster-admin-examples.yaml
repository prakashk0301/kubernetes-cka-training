# Kubernetes Resource Management Examples

This file contains comprehensive examples for resource management, quotas, limits, and Quality of Service (QoS) configurations in Kubernetes 1.32+.

---
# Example 1: Resource Requests and Limits - Basic Configuration

apiVersion: v1
kind: Pod
metadata:
  name: resource-demo-basic
  labels:
    app: demo
    tier: basic
spec:
  containers:
  - name: web-container
    image: nginx:1.25-alpine
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
    env:
    - name: ENVIRONMENT
      value: "development"
  restartPolicy: Always
  terminationGracePeriodSeconds: 30

---
# Example 2: Multi-Container Pod with Different Resource Requirements

apiVersion: v1
kind: Pod
metadata:
  name: multi-container-resources
  labels:
    app: multi-demo
    tier: production
spec:
  containers:
  # Main application container
  - name: app-container
    image: nginx:1.25-alpine
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "256Mi"
        cpu: "500m"
      limits:
        memory: "512Mi"
        cpu: "1000m"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
  
  # Sidecar logging container
  - name: log-sidecar
    image: fluent/fluent-bit:2.2
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
    volumeMounts:
    - name: logs
      mountPath: /var/log
  
  # Monitoring sidecar
  - name: metrics-sidecar
    image: prom/node-exporter:v1.6.1
    args:
    - '--path.rootfs=/host'
    ports:
    - containerPort: 9100
    resources:
      requests:
        memory: "32Mi"
        cpu: "50m"
      limits:
        memory: "64Mi"
        cpu: "100m"
    volumeMounts:
    - name: proc
      mountPath: /host/proc
      readOnly: true
    - name: sys
      mountPath: /host/sys
      readOnly: true
  
  volumes:
  - name: logs
    emptyDir: {}
  - name: proc
    hostPath:
      path: /proc
  - name: sys
    hostPath:
      path: /sys
  
  restartPolicy: Always
  terminationGracePeriodSeconds: 30

---
# Example 3: QoS Classes - Guaranteed

apiVersion: v1
kind: Pod
metadata:
  name: qos-guaranteed-demo
  labels:
    app: guaranteed-qos
    qos-class: guaranteed
  annotations:
    description: "Pod with Guaranteed QoS class - requests equal limits"
spec:
  containers:
  - name: guaranteed-container
    image: busybox:1.36
    command: ["sh", "-c", "while true; do echo 'Running with Guaranteed QoS'; sleep 30; done"]
    resources:
      requests:
        memory: "100Mi"
        cpu: "100m"
      limits:
        memory: "100Mi"  # Requests = Limits for Guaranteed QoS
        cpu: "100m"
  
  # Second container also with equal requests and limits
  - name: guaranteed-sidecar
    image: alpine:3.18
    command: ["sh", "-c", "while true; do echo 'Sidecar with Guaranteed QoS'; sleep 60; done"]
    resources:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "50Mi"
        cpu: "50m"
  
  restartPolicy: Always
  terminationGracePeriodSeconds: 0

---
# Example 4: QoS Classes - Burstable

apiVersion: v1
kind: Pod
metadata:
  name: qos-burstable-demo
  labels:
    app: burstable-qos
    qos-class: burstable
  annotations:
    description: "Pod with Burstable QoS class - has requests but limits are higher"
spec:
  containers:
  - name: burstable-container
    image: nginx:1.25-alpine
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"  # Limits > Requests for Burstable QoS
        cpu: "500m"
    env:
    - name: QOS_CLASS
      value: "Burstable"
  
  # Container with only requests (no limits)
  - name: request-only-container
    image: alpine:3.18
    command: ["sh", "-c", "while true; do echo 'Request-only container'; sleep 45; done"]
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      # No limits defined - still Burstable because pod has some requests
  
  restartPolicy: Always

---
# Example 5: QoS Classes - BestEffort

apiVersion: v1
kind: Pod
metadata:
  name: qos-besteffort-demo
  labels:
    app: besteffort-qos
    qos-class: besteffort
  annotations:
    description: "Pod with BestEffort QoS class - no resource requirements"
spec:
  containers:
  - name: besteffort-container
    image: busybox:1.36
    command: ["sh", "-c", "while true; do echo 'Running with BestEffort QoS - no guarantees'; sleep 20; done"]
    # No resources section = BestEffort QoS
    env:
    - name: QOS_CLASS
      value: "BestEffort"
  
  - name: besteffort-sidecar
    image: alpine:3.18
    command: ["sh", "-c", "while true; do echo 'Sidecar with BestEffort QoS'; sleep 40; done"]
    # No resources for this container either
  
  restartPolicy: Always

---
# Example 6: Resource Quotas - Comprehensive Namespace Quota

apiVersion: v1
kind: ResourceQuota
metadata:
  name: comprehensive-quota
  namespace: resource-demo
spec:
  hard:
    # Compute Resources
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "8"
    limits.memory: 16Gi
    
    # Storage Resources
    requests.storage: 100Gi
    persistentvolumeclaims: "10"
    
    # Object Count Quotas
    pods: "20"
    replicationcontrollers: "5"
    resourcequotas: "1"
    secrets: "10"
    configmaps: "10"
    services: "10"
    services.loadbalancers: "2"
    services.nodeports: "5"
    
    # Extended Resources (example for GPUs)
    requests.nvidia.com/gpu: "2"
    
    # Ephemeral Storage
    requests.ephemeral-storage: 10Gi
    limits.ephemeral-storage: 20Gi

---
# Example 7: Scoped Resource Quotas

apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-terminating
  namespace: resource-demo
spec:
  hard:
    requests.cpu: "1"
    requests.memory: 1Gi
    limits.cpu: "2"
    limits.memory: 2Gi
  scopes: ["Terminating"]  # Only applies to pods with activeDeadlineSeconds

---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-not-terminating
  namespace: resource-demo
spec:
  hard:
    requests.cpu: "3"
    requests.memory: 6Gi
    limits.cpu: "6"
    limits.memory: 12Gi
  scopes: ["NotTerminating"]  # Only applies to long-running pods

---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-besteffort
  namespace: resource-demo
spec:
  hard:
    pods: "5"
  scopes: ["BestEffort"]  # Only applies to BestEffort pods

---
# Example 8: Comprehensive Limit Range

apiVersion: v1
kind: LimitRange
metadata:
  name: comprehensive-limits
  namespace: resource-demo
spec:
  limits:
  # Container-level limits
  - type: Container
    default:
      cpu: "500m"
      memory: "256Mi"
      ephemeral-storage: "1Gi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
      ephemeral-storage: "512Mi"
    min:
      cpu: "50m"
      memory: "64Mi"
      ephemeral-storage: "256Mi"
    max:
      cpu: "2"
      memory: "2Gi"
      ephemeral-storage: "4Gi"
    maxLimitRequestRatio:
      cpu: 10
      memory: 4
      ephemeral-storage: 2
  
  # Pod-level limits (aggregate of all containers)
  - type: Pod
    min:
      cpu: "100m"
      memory: "128Mi"
    max:
      cpu: "4"
      memory: "4Gi"
  
  # PVC limits
  - type: PersistentVolumeClaim
    min:
      storage: "1Gi"
    max:
      storage: "100Gi"

---
# Example 9: Pod with Resource Monitoring

apiVersion: v1
kind: Pod
metadata:
  name: resource-monitoring-demo
  labels:
    app: monitoring-demo
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
spec:
  containers:
  - name: app-with-metrics
    image: nginx:1.25-alpine
    ports:
    - containerPort: 80
    - containerPort: 8080  # Metrics port
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "1000m"
    env:
    - name: ENABLE_METRICS
      value: "true"
    - name: METRICS_PORT
      value: "8080"
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "nginx -s quit; while killall -0 nginx; do sleep 1; done"]

---
# Example 10: Job with Resource Constraints

apiVersion: batch/v1
kind: Job
metadata:
  name: resource-intensive-job
  labels:
    app: batch-job
    type: resource-demo
spec:
  template:
    metadata:
      labels:
        app: batch-job
        type: resource-demo
    spec:
      containers:
      - name: worker
        image: busybox:1.36
        command:
        - /bin/sh
        - -c
        - |
          echo "Starting resource-intensive job..."
          # Simulate CPU and memory intensive work
          for i in $(seq 1 100); do
            echo "Processing batch $i/100"
            dd if=/dev/zero of=/tmp/test$i bs=1M count=10 2>/dev/null
            sleep 1
          done
          echo "Job completed successfully"
        resources:
          requests:
            memory: "512Mi"
            cpu: "1000m"
            ephemeral-storage: "2Gi"
          limits:
            memory: "1Gi"
            cpu: "2000m"
            ephemeral-storage: "4Gi"
        env:
        - name: JOB_TYPE
          value: "resource-intensive"
        - name: WORKER_ID
          value: "worker-001"
      restartPolicy: Never
      activeDeadlineSeconds: 300  # 5 minutes timeout
  backoffLimit: 3
  completions: 1
  parallelism: 1

---
# Example 11: Deployment with Resource Management

apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-managed-app
  labels:
    app: managed-app
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: managed-app
  template:
    metadata:
      labels:
        app: managed-app
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
    spec:
      containers:
      - name: app
        image: nginx:1.25-alpine
        ports:
        - containerPort: 80
        - containerPort: 8080
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"
        env:
        - name: APP_ENV
          value: "production"
        - name: REPLICA_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /etc/nginx/conf.d
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: nginx-config
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - managed-app
              topologyKey: kubernetes.io/hostname

---
# Example 12: Pod Disruption Budget

apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: managed-app-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: managed-app

---
# Example 13: Priority Class for Critical Workloads

apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "High priority class for critical applications"

---
# Example 14: Pod with Priority Class

apiVersion: v1
kind: Pod
metadata:
  name: critical-app
  labels:
    app: critical
    priority: high
spec:
  priorityClassName: high-priority
  containers:
  - name: critical-container
    image: nginx:1.25-alpine
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
    env:
    - name: PRIORITY_CLASS
      value: "high-priority"
  restartPolicy: Always

---
# Example 15: Resource Testing Script (Embedded)

# test-resources.sh
#!/bin/bash
echo "# Resource Management Testing Script"
echo "# This script tests various resource configurations"
echo ""

echo "## 1. Creating test namespace..."
kubectl create namespace resource-demo --dry-run=client -o yaml | kubectl apply -f -

echo "## 2. Applying resource quota..."
kubectl apply -f quota-cpu-memory.yaml -n resource-demo

echo "## 3. Applying limit range..."
kubectl apply -f limits.yaml -n resource-demo

echo "## 4. Testing QoS classes..."
kubectl apply -f qos-guaranteed.yaml -n resource-demo
kubectl apply -f qos-burstable.yaml -n resource-demo
kubectl apply -f qos-besteffort.yaml -n resource-demo

echo "## 5. Checking resource usage..."
kubectl top pods -n resource-demo

echo "## 6. Describing quotas and limits..."
kubectl describe quota -n resource-demo
kubectl describe limitrange -n resource-demo

echo "## 7. Getting pod QoS classes..."
kubectl get pods -n resource-demo -o custom-columns="NAME:.metadata.name,QOS:.status.qosClass"

echo "## 8. Monitoring events..."
kubectl get events -n resource-demo --sort-by='.lastTimestamp'

echo ""
echo "Testing completed. Check the output above for any issues."
